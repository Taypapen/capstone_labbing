{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from fastai.layers import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def noop():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def _3d_block(in_size, out_size, kernel_size, stride, padding, bias=False, relu_type='prelu'):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(in_size, out_size, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "        nn.BatchNorm3d(out_size),\n",
    "        nn.PReLU(num_parameters=out_size) if relu_type== 'prelu' else nn.ReLU()\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _bottleneck_conv_block(ni, nf, stride):\n",
    "    return nn.Sequential(\n",
    "        ConvLayer(ni,nf//4, 1),\n",
    "        ConvLayer(nf//4,nf//4, stride=stride),\n",
    "        ConvLayer(nf//4, nf, 1, act_cls=None, norm_type=NormType.BatchZero)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _conv_block(ni,nf,stride):\n",
    "    return nn.Sequential(\n",
    "        ConvLayer(ni,nf, stride=stride),\n",
    "        ConvLayer(nf, nf, 1, act_cls=None, norm_type=NormType.BatchZero)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=1, bottled=True):\n",
    "        self.convs = _bottleneck_conv_block(ni, nf, stride) if bottled else _conv_block(ni, nf, stride)\n",
    "        self.idconv = noop if ni==nf else ConvLayer(ni, nf, 1, act_cls=None)\n",
    "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return F.relu(self.convs(x) + self.idconv(self.pool(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResNet(nn.Sequential):\n",
    "    def __init__(self, layers, relu_type = 'relu', expansion=1):\n",
    "\n",
    "        self.relu_type= relu_type\n",
    "        self.block_sizes = [64, 64, 128, 256, 512]\n",
    "        for i in range(1, len(self.block_sizes)): self.block_sizes *= expansion\n",
    "        blocks = [self._make_layer(*o) for o in enumerate(layers)]\n",
    "\n",
    "        super().__init__(*blocks, nn.AdaptiveAvgPool2d(1))\n",
    "        #self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        #self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        #self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        #self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        #self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def _make_layer(self, idx, n_layers):\n",
    "        stride = 1 if idx==0 else 2\n",
    "        ch_in, ch_out = self.block_sizes[idx:idx+2]\n",
    "        return nn.Sequential(*[\n",
    "            ResBlock(ch_in if i==0 else ch_out, ch_out, stride if i==0 else 1)\n",
    "            for i in range(n_layers)\n",
    "        ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}