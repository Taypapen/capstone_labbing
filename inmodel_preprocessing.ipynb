{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    \"\"\"Compose several preprocess together.\n",
    "    Args:\n",
    "        preprocess (list of ``Preprocess`` objects): list of preprocess to compose.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, preprocess):\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        for t in self.preprocess:\n",
    "            sample = t(sample)\n",
    "        return sample\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.preprocess:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n",
    "\n",
    "class RgbToGray(object):\n",
    "    \"\"\"Convert image to grayscale.\n",
    "    Converts a numpy.ndarray (H x W x C) in the range\n",
    "    [0, 255] to a numpy.ndarray of shape (H x W x C) in the range [0.0, 1.0].\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, frames):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (numpy.ndarray): Image to be converted to gray.\n",
    "        Returns:\n",
    "            numpy.ndarray: grey image\n",
    "        \"\"\"\n",
    "        frames = np.stack([cv2.cvtColor(_, cv2.COLOR_RGB2GRAY) for _ in frames], axis=0)\n",
    "        return frames\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Normalize a ndarray image with mean and standard deviation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, frames):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized Tensor image.\n",
    "        \"\"\"\n",
    "        frames = (frames - self.mean) / self.std\n",
    "        return frames\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__+'(mean={0}, std={1})'.format(self.mean, self.std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "video_array = np.load('/home/taylorpap/Bootcamp/CroppedLRW/ABOUT/test/ABOUT_00001.npz')['data']\n",
    "print(video_array.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def dataset_preprocessing(dataset_path, labels_file_path, paths_pickle):\n",
    "    with open(labels_file_path, \"r\") as f:\n",
    "        classes = f.read().split('\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def sparse_acc(true_labels, predicted_labels):\n",
    "    assert len(true_labels) == len(predicted_labels)\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for i in len(true_labels):\n",
    "\n",
    "        if np.argmax(predicted_labels[i]) == true_labels[i]:\n",
    "            correct+=1\n",
    "\n",
    "    return correct/len(true_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_preprocessing_pipelines(modality):\n",
    "    # -- preprocess for the video stream\n",
    "    preprocessing = {}\n",
    "    # -- LRW config\n",
    "    if modality == 'video':\n",
    "        crop_size = (88, 88)\n",
    "        (mean, std) = (0.421, 0.165)\n",
    "        preprocessing['train'] = Compose([\n",
    "                                    Normalize( 0.0,255.0 ),\n",
    "                                    RandomCrop(crop_size),\n",
    "                                    HorizontalFlip(0.5),\n",
    "                                    Normalize(mean, std) ])\n",
    "\n",
    "        preprocessing['val'] = Compose([\n",
    "                                    Normalize( 0.0,255.0 ),\n",
    "                                    CenterCrop(crop_size),\n",
    "                                    Normalize(mean, std) ])\n",
    "\n",
    "        preprocessing['test'] = preprocessing['val']\n",
    "    return preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}