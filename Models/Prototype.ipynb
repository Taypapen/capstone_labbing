{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from pytorch_nn import Lipread2\n",
    "from Model_training_blocks import FullTrainer\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasetloadingpy import dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Import all possible words as list\n",
    "words_list_file = '/home/taylorpap/Bootcamp/wordlist.txt'\n",
    "words_list = get_wordslist_from_txt_file(words_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Used for training From scratch (To generate weights before full scale)\n",
    "temp_words_list = []\n",
    "for index in range(1, len(words_list), 4):\n",
    "    temp_words_list.append(words_list[index])\n",
    "print(len(temp_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create DataLoader for training model\n",
    "data_path = '/media/taylorpap/2TBM2/Dataset_2/GreyCropped'\n",
    "datasets = dataloaders(data_dir=data_path, label_fp=temp_words_list, batch_size=64, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create Model and specify number of classes\n",
    "model = Lipread2(len(temp_words_list))\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "#Specify the checkpoint to load (Used for second FullTrainer object below)\n",
    "checkpoint_path = '/home/taylorpap/Bootcamp/Lipread2_full_scale/ckpt.pth.tar'\n",
    "#Specify where checkpoint should be saved after each epoch\n",
    "save_direc = '/home/taylorpap/Bootcamp/Lipread2_full_scale/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Train model on smaller Dataset using larger batch size of 64, and number of epochs as 80 with a high learning rate for initial weights\n",
    "train_model = FullTrainer(model, datasets, criterion=nn.CrossEntropyLoss(), epochs=80, save_dir=save_direc, lr=0.009)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last Cell Output before cancel:\n",
    "```\n",
    "100%|██████████| 98/98 [00:07<00:00, 13.18it/s]\n",
    "6249 in total\tCR: 0.847655624899984\n",
    "val Epoch:\t33\tLoss val: 0.5631\tAcc val:0.8477, LR: 0.005890576474687263\n",
    "Epoch len: 278.1077609062195 Estimated Remaining: 213.21595002810162 Min\n",
    "Current Epoch: 34\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Stopped Early to decrease learning rate, loading from checkpoint\n",
    "train_model = FullTrainer(model, datasets, criterion=nn.CrossEntropyLoss().cuda(), epochs=80, save_dir=save_direc, state_path=checkpoint_path, lr=0.0009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font size='6'>\n",
    "Scaled Model is made far smaller than initial attempts in order to speed up training time and efficiency of the model. This is done because of the huge scale of the dataset where time ends up being a large factor. In the real world, this model would also be expected to be fast enough for close to real time analysis, although another model would likely be needed for checking sentences of words as opposed to single word predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Validated accuracy still acceptable on larger portion of dataset\n",
    "#Using created weights to begin training full scale model\n",
    "model = Lipread2(len(words_list))\n",
    "#Move model to Cuda for faster training/performance\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "data_path = '/media/taylorpap/2TBM2/Dataset_2/GreyCropped'\n",
    "#Create new dataset object with full words list\n",
    "datasets = dataloaders(data_dir=data_path, label_fp=words_list, batch_size=64, workers=16)\n",
    "#Load above checkpoint for model weights. FullTrainer class uses only matching weights\n",
    "checkpoint_path = '/home/taylorpap/Bootcamp/Lipread2_full_scale/ckpt.pth.tar'\n",
    "save_direc = '/home/taylorpap/Bootcamp/Lipread2_actual_full_scale/'\n",
    "train_model = FullTrainer(model, datasets, criterion=nn.CrossEntropyLoss().cuda(), epochs=80, save_dir=save_direc, state_path=checkpoint_path, model_weights_only=True, lr=0.009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font size='6'>\n",
    "Despite the model being so lightweight, the total training time ended up being nearly 24 Hours total.\n",
    "\n",
    "After training, Model Achieves about 80% Accuracy on full 500 word dataset. It is possible that extra layers could achieve a slightly higher score, but this implementation is fairly effecient and could be useful for ensembling multiple models together for the final result.\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
